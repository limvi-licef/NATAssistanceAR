{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### Author: Anthony Melin\n",
    "### Date: 2019 August 14\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile, move\n",
    "from PIL import Image\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "\n",
    "from ObjectDetection import *\n",
    "\n",
    "from utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and classes\n",
    "### Build labelmap file\n",
    "Labelmap files provide the associated name object to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "def newLabelmapItem(index, name):\n",
    "\n",
    "    item  = \"item {\\n\"\n",
    "    item += \"    id: {}\\n\".format(index)\n",
    "    item += \"    name: '{}'\\n\".format(name)\n",
    "    item += \"}\\n\"\n",
    "\n",
    "    return item\n",
    "\n",
    "############################################################################################\n",
    "class Labelmap:\n",
    "    \n",
    "    ########################################################################################\n",
    "    def __init__(self, filename_src, filename_dst=None):\n",
    "        \n",
    "        self.filename_src = filename_src\n",
    "        \n",
    "        if filename_dst == None:\n",
    "            filename_dst = filename_src.replace(\".txt\", \".pbtxt\")\n",
    "        self.filename_dst = filename_dst\n",
    "        \n",
    "    \n",
    "    ########################################################################################\n",
    "    def GetCategories(self):\n",
    "\n",
    "        with open(self.filename_src, \"r\") as file:\n",
    "            self.categories = file.read().split('\\n')\n",
    "            self.categories.remove(\"\")\n",
    "\n",
    "        return self.categories\n",
    "    \n",
    "    ########################################################################################\n",
    "    def Build(self):\n",
    "\n",
    "        with open(self.filename_dst, \"w\") as file:\n",
    "            \n",
    "            for i, category in enumerate(self.GetCategories()):\n",
    "                item = newLabelmapItem(i+1, category)\n",
    "                file.write(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data to TFRecord\n",
    "TFRecord is a file format where all data are stored including both images and annotations.\n",
    "#### Get annotations from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "class Annotation(dict):\n",
    "    \n",
    "    ####################################################################################\n",
    "    def __init__(self, filename, classes):\n",
    "        \n",
    "        self[\"filename\"] = filename\n",
    "        self.classes = classes\n",
    "        \n",
    "        \n",
    "    ####################################################################################\n",
    "    def SetArrays(self):\n",
    "        \n",
    "        self[\"indexes\"] = []\n",
    "        self[\"classes\"] = []\n",
    "        self[\"xmins\"] = []\n",
    "        self[\"ymins\"] = []\n",
    "        self[\"xmaxs\"] = []\n",
    "        self[\"ymaxs\"] = []\n",
    "        \n",
    "    \n",
    "    ####################################################################################\n",
    "    def AppendLine(self, line):\n",
    "        \n",
    "        index, center_x, center_y, width, height = line.split(\" \")\n",
    "    \n",
    "        self[\"indexes\"].append(int(index)+1)\n",
    "        self[\"classes\"].append(self.classes[int(index)].encode())\n",
    "        self[\"xmins\"].append(float(center_x)-float(width)/2)\n",
    "        self[\"ymins\"].append(float(center_y)-float(height)/2)\n",
    "        self[\"xmaxs\"].append(float(center_x)+float(width)/2)\n",
    "        self[\"ymaxs\"].append(float(center_y)+float(height)/2)\n",
    "        \n",
    "        \n",
    "    ####################################################################################\n",
    "    def Build(self):\n",
    "        \n",
    "        self[\"image_name\"] = self[\"filename\"].replace(\".txt\",\".jpg\")\n",
    "        self[\"image_format\"] = b\"jpg\"\n",
    "        self[\"width\"], self[\"height\"] = Image.open(self[\"image_name\"]).size\n",
    "        \n",
    "        with open(self[\"image_name\"], \"rb\") as f:\n",
    "            self[\"encoded_jpg\"] = f.read()\n",
    "        \n",
    "        with open(self[\"filename\"], \"r\") as file:\n",
    "            lines = filter(None, file.read().split('\\n'))\n",
    "            \n",
    "        self.SetArrays()\n",
    "        for line in lines:\n",
    "            self.AppendLine(line)\n",
    "    \n",
    "\n",
    "\n",
    "########################################################################################\n",
    "def IsAnnotationFile(filename):\n",
    "    \n",
    "    if filename.endswith(\".txt\") and filename != \"classes.txt\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "########################################################################################\n",
    "def GetAnnotationFilenames(path):\n",
    "    \n",
    "    return [os.path.abspath(os.path.join(path, filenames)) for filenames in os.listdir(path) if IsAnnotationFile(filenames)]\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "def BuildAnnotationList(path, classes):\n",
    "    \n",
    "    annotationList = []\n",
    "    for filename in GetAnnotationFilenames(path):\n",
    "        annotation = Annotation(filename, classes)\n",
    "        annotation.Build()\n",
    "        annotationList.append(annotation)\n",
    "        \n",
    "    return annotationList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing .record (TFRecord) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "def WriteTFRecord(filename, annotations):\n",
    "    \n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        \n",
    "        for annotation in annotations:\n",
    "\n",
    "            features = tf.train.Features(feature={\n",
    "                'image/height': dataset_util.int64_feature(annotation[\"height\"]),\n",
    "                'image/width': dataset_util.int64_feature(annotation[\"width\"]),\n",
    "                \n",
    "                'image/filename': dataset_util.bytes_feature(annotation[\"filename\"].encode()),\n",
    "                'image/source_id': dataset_util.bytes_feature(annotation[\"filename\"].encode()),\n",
    "                'image/encoded': dataset_util.bytes_feature(annotation[\"encoded_jpg\"]),\n",
    "                'image/format': dataset_util.bytes_feature(annotation[\"image_format\"]),\n",
    "\n",
    "                'image/object/bbox/xmin': dataset_util.float_list_feature(annotation[\"xmins\"]),\n",
    "                'image/object/bbox/xmax': dataset_util.float_list_feature(annotation[\"xmaxs\"]),\n",
    "                'image/object/bbox/ymin': dataset_util.float_list_feature(annotation[\"ymins\"]),\n",
    "                'image/object/bbox/ymax': dataset_util.float_list_feature(annotation[\"ymaxs\"]),\n",
    "                'image/object/class/text': dataset_util.bytes_list_feature(annotation[\"classes\"]),\n",
    "                'image/object/class/label': dataset_util.int64_list_feature(annotation[\"indexes\"]),\n",
    "            })\n",
    "\n",
    "            writer.write(tf.train.Example(features=features).SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model\n",
    "If it was not already used, the object detector directory will be downloaded on the tensorflow download base. The directory provide a config file to use for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "def extract(model_name, target_dir):\n",
    "    \n",
    "    MODEL_ZIPFILE = model_name + '.tar.gz'\n",
    "    MODEL_PATH = os.path.join(\"cnn\", MODEL_ZIPFILE)\n",
    "    \n",
    "    tar_file = tarfile.open(MODEL_PATH)\n",
    "    for file in tar_file.getmembers():\n",
    "        tar_file.extract(file, target_dir)\n",
    "        \n",
    "\n",
    "########################################################################################\n",
    "def download(model_name):\n",
    "    \n",
    "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    MODEL_ZIPFILE = model_name + '.tar.gz'\n",
    "    MODEL_URL = DOWNLOAD_BASE + MODEL_ZIPFILE\n",
    "    \n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(MODEL_URL, MODEL_ZIPFILE)\n",
    "    opener.cleanup()\n",
    "    opener.close()\n",
    "    \n",
    "\n",
    "########################################################################################\n",
    "def need_to_download(model_name):\n",
    "    \n",
    "    MODEL_ZIPFILE = model_name + '.tar.gz'\n",
    "    \n",
    "    if MODEL_ZIPFILE not in os.listdir(\"cnn\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "\n",
    "########################################################################################\n",
    "def move_to_cnn_dir(model_name):\n",
    "\n",
    "    SRC = model_name + '.tar.gz'\n",
    "    DST = os.path.join(\"cnn\", model_name + '.tar.gz')\n",
    "    move(SRC, DST)\n",
    "    \n",
    "    \n",
    "########################################################################################\n",
    "def download_if_needed(model_name):\n",
    "    \n",
    "    if need_to_download(model_name):\n",
    "        download(model_name)\n",
    "        move_to_cnn_dir(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete the .config file\n",
    "The .config file set the trainning by specify parameters like loss function or number of evaluation to do. Path to train and test tfrecord file must be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "def complete_val(lines, param, val, start):\n",
    "    \n",
    "    for i in range(start, len(lines)):\n",
    "        \n",
    "        if param in lines[i] :\n",
    "            lines[i] = param + ': ' + val\n",
    "            return i+1\n",
    "        \n",
    "    return i+1\n",
    "\n",
    "########################################################################################\n",
    "def complete_values(path, parameters):\n",
    "    \n",
    "    # read the file to get its lines\n",
    "    with open(path) as file:\n",
    "        lines = file.read().split(\"\\n\")\n",
    "    \n",
    "    # loop over lines for setting parameters\n",
    "    i = 0\n",
    "    for param, value in parameters:\n",
    "        \n",
    "        if type(value) == str:\n",
    "            val = '\"{}\"'.format(value.replace(\"\\\\\", \"/\")) # backslash must be replace in config file and \" inserted\n",
    "        elif type(value) == bool:\n",
    "            val = str(value).lower()\n",
    "        else:\n",
    "            val = str(value)\n",
    "        \n",
    "        i = complete_val(lines, param, val, i)\n",
    "        if i == len(lines): break\n",
    "            \n",
    "    # update the file\n",
    "    with open(path, \"w\") as file:\n",
    "        for line in lines:\n",
    "            file.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "def add_train_module(path):\n",
    "    \n",
    "    TRAIN_SCRIPT_SRC = os.path.join(object_detection_path(), \"legacy\", \"train.py\")\n",
    "    TRAIN_SCRIPT_DST = os.path.join(path, \"train.py\")\n",
    "    \n",
    "    with open(TRAIN_SCRIPT_DST, \"w\") as dst:\n",
    "        dst.write(\"from ObjectDetection import *\\n\")\n",
    "        \n",
    "        # open read only\n",
    "        with open(TRAIN_SCRIPT_SRC, \"r\") as src:\n",
    "            dst.write(src.read())\n",
    "            \n",
    "\n",
    "########################################################################################\n",
    "def gen_train_bat(work_dir, training_dir, config_path):\n",
    "    \n",
    "    BAT_FILE = os.path.join(work_dir, \"train.bat\")\n",
    "    TRAIN_SCRIPT_PATH = os.path.join(object_detection_path(), \"legacy\", \"train.py\")\n",
    "\n",
    "    CMD = \"python train.py --logtostderr --train_dir={} --pipeline_config_path={}\".format(training_dir, config_path)\n",
    "    with open(BAT_FILE, \"w\") as file: file.write(CMD)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"WORK_DIR\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(WORK_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(WORK_DIR, \"test\")\n",
    "\n",
    "TRAINING_DIR = os.path.join(WORK_DIR, \"training\")\n",
    "\n",
    "MODEL_NAME = \"MODEL_NAME\"\n",
    "CONFIG_FILE = \"CONFIG_FILE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(TRAINING_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train filenames\n",
    "TRAIN_CLASSES = os.path.join(TRAIN_DIR, \"classes.txt\")\n",
    "TRAIN_LABELMAP = os.path.join(TRAINING_DIR, \"train.pbtxt\")\n",
    "\n",
    "# test filenames\n",
    "TEST_CLASSES = os.path.join(TEST_DIR, \"classes.txt\")\n",
    "TEST_LABELMAP = os.path.join(TRAINING_DIR, \"test.pbtxt\")\n",
    "\n",
    "# build labelmaps\n",
    "train_labelmap = Labelmap(TRAIN_CLASSES, TRAIN_LABELMAP)\n",
    "train_labelmap.Build()\n",
    "\n",
    "test_labelmap = Labelmap(TEST_CLASSES, TEST_LABELMAP)\n",
    "test_labelmap.Build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RECORD = os.path.join(TRAINING_DIR, \"train.record\")\n",
    "TEST_RECORD = os.path.join(TRAINING_DIR, \"test.record\")\n",
    "\n",
    "train_annotations = BuildAnnotationList(TRAIN_DIR, train_labelmap.GetCategories())\n",
    "test_annotations = BuildAnnotationList(TEST_DIR, test_labelmap.GetCategories())\n",
    "    \n",
    "WriteTFRecord(TRAIN_RECORD, train_annotations)\n",
    "WriteTFRecord(TEST_RECORD, test_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model importation and config\n",
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_if_needed(MODEL_NAME)\n",
    "extract(MODEL_NAME, TRAINING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_SRC = os.path.join(object_detection_path(), \"samples/configs\", CONFIG_FILE)\n",
    "CONFIG_DST = os.path.join(TRAINING_DIR, CONFIG_FILE)\n",
    "\n",
    "copyfile(CONFIG_SRC, CONFIG_DST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_FILE = os.path.join(TRAINING_DIR, MODEL_NAME, \"model.ckpt\")\n",
    "\n",
    "complete_values(CONFIG_DST, [\n",
    "                (\"num_classes\", len(train_labelmap.categories)),\n",
    "                (\"fine_tune_checkpoint\", CHECK_FILE),\n",
    "                (\"input_path\", TRAIN_RECORD),\n",
    "                (\"label_map_path\", TRAIN_LABELMAP),\n",
    "                (\"num_examples\", 150),\n",
    "                (\"input_path\", TEST_RECORD),\n",
    "                (\"label_map_path\", TEST_LABELMAP),\n",
    "                (\"shuffle\", True)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train files (.py and .bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy object detection initializer module\n",
    "OBJECT_DETECTION_DST = os.path.join(WORK_DIR, \"ObjectDetection.py\")\n",
    "copyfile(\"ObjectDetection.py\", OBJECT_DETECTION_DST)\n",
    "\n",
    "add_train_module(WORK_DIR)\n",
    "gen_train_bat(WORK_DIR, TRAINING_DIR, CONFIG_DST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
